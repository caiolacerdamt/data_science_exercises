{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_path, target_size, preprocess_input_fn):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input_fn(x)\n",
    "    return x\n",
    "\n",
    "img_path = 'elefante2.webp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "ResNet50 Prediction:\n",
      "('n04399382', 'teddy', np.float32(0.80986404))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ResNet50\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "\n",
    "model_resnet50 = ResNet50(weights='imagenet')\n",
    "img_resnet = load_and_preprocess_image(img_path, (224, 224), preprocess_input)\n",
    "preds_resnet = model_resnet50.predict(img_resnet)\n",
    "\n",
    "print(\"ResNet50 Prediction:\")\n",
    "print(decode_predictions(preds_resnet, top=1)[0][0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "InceptionV3 Predictions:\n",
      "('n04399382', 'teddy', np.float32(0.9672541))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# InceptionV3\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess, decode_predictions as inception_decode\n",
    "\n",
    "model_inception = InceptionV3(weights='imagenet')\n",
    "img_inception = load_and_preprocess_image(img_path, (299, 299), inception_preprocess)\n",
    "preds_inception = model_inception.predict(img_inception)\n",
    "\n",
    "print('InceptionV3 Predictions:')\n",
    "print(inception_decode(preds_inception, top=1)[0][0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763ms/step\n",
      "MobileNetV2 Predictions:\n",
      "('n04399382', 'teddy', np.float32(0.9858964))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input as mobilenet_preprocess, decode_predictions as mobilenet_decode\n",
    "\n",
    "model_mobilenet = MobileNetV2(weights='imagenet')\n",
    "img_mobilenet = load_and_preprocess_image(img_path, (224, 224), mobilenet_preprocess)\n",
    "preds_mobilenet = model_mobilenet.predict(img_mobilenet)\n",
    "\n",
    "print('MobileNetV2 Predictions:')\n",
    "print(mobilenet_decode(preds_mobilenet, top=1)[0][0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "DenseNet121 Predictions:\n",
      "('n04399382', 'teddy', np.float32(0.9774095))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DenseNet121\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess, decode_predictions as densenet_decode\n",
    "\n",
    "model_densenet = DenseNet121(weights='imagenet')\n",
    "img_densenet = load_and_preprocess_image(img_path, (224, 224), densenet_preprocess)\n",
    "preds_densenet = model_densenet.predict(img_densenet)\n",
    "\n",
    "print('DenseNet121 Predictions:')\n",
    "print(densenet_decode(preds_densenet, top=1)[0][0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "EfficientNetB0 Predictions:\n",
      "('n04399382', 'teddy', np.float32(0.5606458))\n"
     ]
    }
   ],
   "source": [
    "# EfficientNetB0\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess, decode_predictions as efficientnet_decode\n",
    "\n",
    "model_efficientnet = EfficientNetB0(weights='imagenet')\n",
    "img_efficientnet = load_and_preprocess_image(img_path, (224, 224), efficientnet_preprocess)\n",
    "preds_efficientnet = model_efficientnet.predict(img_efficientnet)\n",
    "\n",
    "print('EfficientNetB0 Predictions:')\n",
    "print(efficientnet_decode(preds_efficientnet, top=1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 142ms/step - accuracy: 0.3103 - loss: 2.8550 - val_accuracy: 0.2845 - val_loss: 4.3732\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 144ms/step - accuracy: 0.5091 - loss: 1.8296 - val_accuracy: 0.4446 - val_loss: 3.2883\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 142ms/step - accuracy: 0.5804 - loss: 1.5202 - val_accuracy: 0.4816 - val_loss: 2.4845\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 142ms/step - accuracy: 0.6289 - loss: 1.2972 - val_accuracy: 0.4932 - val_loss: 2.7047\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 142ms/step - accuracy: 0.6767 - loss: 1.1115 - val_accuracy: 0.5076 - val_loss: 2.5553\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 143ms/step - accuracy: 0.7191 - loss: 0.9518 - val_accuracy: 0.4963 - val_loss: 3.3625\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 146ms/step - accuracy: 0.7534 - loss: 0.8154 - val_accuracy: 0.5507 - val_loss: 2.7102\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 148ms/step - accuracy: 0.7856 - loss: 0.7031 - val_accuracy: 0.5423 - val_loss: 2.6309\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 144ms/step - accuracy: 0.8088 - loss: 0.6168 - val_accuracy: 0.5450 - val_loss: 2.7530\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 138ms/step - accuracy: 0.8288 - loss: 0.5467 - val_accuracy: 0.5732 - val_loss: 2.5237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x277a023f6b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False \n",
    "\n",
    "for layer in base_model.layers[-20:]:  \n",
    "    layer.trainable = True \n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    " \n",
    "predictions = Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
